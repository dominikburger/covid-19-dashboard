{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import plotly\n",
    "import shapely\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "pd.set_option('display.max_columns', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "GEO_INFO = ['Lat', 'Long_']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get project top directory \n",
    "base_dir = Path(os.getcwd()).parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "csse_data = base_dir / 'data/external/csse_data/csse_covid_19_data'\n",
    "daily_data = csse_data / 'csse_covid_19_daily_reports/'\n",
    "ts_data = csse_data / 'csse_covid_19_time_series'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "def get_daily_csv(path=str(daily_data) + '/*.csv'):\n",
    "    path = glob.glob(path)\n",
    "    file_list = [os.path.basename(file) for file in path]\n",
    "    return sorted(file_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare geo data from csse "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_geo_column(lat=None, long=None):\n",
    "    wkt_string = f'POINT ({lat} {long})'\n",
    "    return shapely.wkt.loads(wkt_string)\n",
    "\n",
    "geo_mapper = {\n",
    "    'US': 'New York',\n",
    "    'Canada': 'Quebec',\n",
    "    'China': 'Beijing',\n",
    "    'Australia': 'Australian Capital Territory',\n",
    "    # 'United Kingdom': np.nan,\n",
    "    # 'Netherlands': np.nan,\n",
    "    # 'Denmark': np.nan,\n",
    "    # 'France': np.nan\n",
    "}\n",
    "\n",
    "# get most recent daily report\n",
    "filepath = daily_data / get_daily_csv()[-1]\n",
    "\n",
    "COLUMN_LIST = ['Country_Region', 'Province_State', 'Lat', 'Long_']\n",
    "INDEX = ['Country_Region', 'Province_State']\n",
    "df = pd.read_csv(filepath, usecols=COLUMN_LIST)\n",
    "\n",
    "# create point wkt and initialize geodataframe\n",
    "df.loc[:, 'geometry'] = df.apply(lambda row: create_geo_column(row['Long_'], row['Lat']), axis=1)\n",
    "df = df.drop(columns=['Long_', 'Lat'])\n",
    "df = gpd.GeoDataFrame(df, geometry='geometry', crs='EPSG:4326')\n",
    "\n",
    "# get a list of unique country names and get dataframe of countries with main provinces\n",
    "country_list = df['Country_Region'].unique()\n",
    "mask = (df['Country_Region'].isin(country_list)) & (pd.isna(df['Province_State']))\n",
    "df_clean = df[mask]\n",
    "\n",
    "# select a specific province for each country with multiple province entries\n",
    "# the province is specified in the 'geo_mapper' object\n",
    "for country, province in geo_mapper.items():\n",
    "    mask = (df['Country_Region'] == country) & (df['Province_State'] == province)\n",
    "    df_temp = df[mask].dissolve('Province_State').reset_index()\n",
    "    df_temp.loc[:, 'geometry'] = df_temp.loc[:, 'geometry'].representative_point()\n",
    "    \n",
    "    df_clean = df_clean.append(df_temp)\n",
    "    df_clean = df_clean.sort_values('Country_Region')\n",
    "    df_clean = df_clean.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge geo data from naturalearthdata with csse data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import plotly\n",
    "import shapely\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "pd.set_option('display.max_columns', 1000)\n",
    "\n",
    "# get project top directory \n",
    "base_dir = Path(os.getcwd()).parent\n",
    "geo_data = base_dir / 'data/external/geo_data/' / 'ne_50m_admin_0_countries.zip'\n",
    "\n",
    "# load geodataframe\n",
    "gdf = gpd.read_file('zip://' + str(geo_data), crs='EPSG:4326')\n",
    "\n",
    "# subset dataframe to relevant columns\n",
    "COLUMNS = ['NAME_EN', 'geometry']\n",
    "gdf_clean = gdf[COLUMNS]\n",
    "\n",
    "# perform spatial join and perform cleaning steps \n",
    "gdf_clean = gpd.sjoin(gdf, df_clean, how='left')\n",
    "gdf_clean = gdf_clean[['Country_Region', 'NAME_EN', 'geometry']]\n",
    "gdf_clean = gdf_clean.sort_values('NAME_EN')\n",
    "gdf_clean = gdf_clean.rename(columns={'NAME_EN': 'name_geo'})\n",
    "gdf_clean = gdf_clean.reset_index(drop=True)\n",
    "\n",
    "# save cleaned dataset with geographical references to disk\n",
    "outputfile = base_dir / 'data/processed/' / 'georeference.json'\n",
    "gdf_clean.to_file(outputfile, driver=\"GeoJSON\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
